{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0759f9c",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf789cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from stats import *\n",
    "from utils import *\n",
    "import visual as vi\n",
    "from Inlier_Thresholder import Inlier_Thresholder\n",
    "import scipy.io as spi\n",
    "from time import time\n",
    "import os\n",
    "import seaborn as sns\n",
    "from itertools import chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b6091",
   "metadata": {},
   "source": [
    "# Initialize the paths to the files and variables containing the data\n",
    "\n",
    "- **names**    contains the names of the files\n",
    "\n",
    "- **mat_data**    dictionary with keys= file names ; values = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fab5e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'C:/Users/carlo/IACV PROJECT/adelH'\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(directory)\n",
    "\n",
    "# Filter out only the .mat files\n",
    "names = [file for file in files if file.endswith('.mat')]\n",
    "\n",
    "# Load each .mat file\n",
    "mat_data = {}\n",
    "for file in names:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    mat_data[file] = spi.loadmat(file_path)\n",
    "    \n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c539a10b",
   "metadata": {},
   "source": [
    "# LMEDS inlier threshold computation and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9817c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameter, how many files to analyse\n",
    "number_of_data_to_analyse=len(names)\n",
    "\n",
    "\n",
    "\n",
    "silhouette_scores = [[] for i in range(number_of_data_to_analyse)]\n",
    "silhouette_avgs = [[] for i in range(number_of_data_to_analyse)]\n",
    "labels_array = [[] for i in range(number_of_data_to_analyse)]\n",
    "residuals = []\n",
    "values_array = [[] for i in range(number_of_data_to_analyse)]\n",
    "thresholds = [[] for i in range(number_of_data_to_analyse)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(number_of_data_to_analyse):\n",
    "    data=mat_data[names[i]]\n",
    "    res=compute_inliers_residual_curve(data)\n",
    "    residuals.append(res)\n",
    "\n",
    "    for j in range(len(res)):\n",
    "        anomaly_detector=Inlier_Thresholder(res[j], type=\"H\")\n",
    "\n",
    "        labels, threshold=anomaly_detector.use_best_method()  # use best method among the statistical ones, best according to silhouette\n",
    "        \n",
    "        if len(np.unique(labels))!=1:\n",
    "            thresholds[i].append(threshold)\n",
    "            labels_array[i].append(labels)\n",
    "            silhouette_scr, silhouette_avg, values = silhouette_score_and_average(res[j], labels)\n",
    "            silhouette_scores[i].append(silhouette_scr)\n",
    "            silhouette_avgs[i].append(silhouette_avg)\n",
    "            values_array[i].append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43bda54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(silhouette_scores)):\n",
    "    for j in range(len(silhouette_scores[i])):\n",
    "        plot_silhouette(silhouette_scores[i][j], labels_array[i][j], silhouette_avgs[i][j], values_array[i][j], -thresholds[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3857b06",
   "metadata": {},
   "source": [
    "# Plot statistics on inlier thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623e19be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_errors(errors):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(errors, bins='auto',\n",
    "                 kde=True)  # kde=True plots a kernel density estimate along with the histogram\n",
    "\n",
    "    # Label the axes and add a title\n",
    "    plt.xlabel(\"Projection Error Average\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(\"Distribution of Projection errors Scores LMEDS\")\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0, max(errors))\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847106b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram to visualize the distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(list(chain.from_iterable(silhouette_avgs)), bins='auto', kde=True)  # kde=True plots a kernel density estimate along with the histogram\n",
    "\n",
    "# Label the axes and add a title\n",
    "plt.xlabel(\"Silhouette Score\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Distribution of Silhouette Scores\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlim(-1, 1)  # Set limits for silhouette scores (typically between -1 and 1)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d399c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram to visualize the distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(list(chain.from_iterable(thresholds)), bins='auto', kde=True)  # kde=True plots a kernel density estimate along with the histogram\n",
    "\n",
    "# Label the axes and add a title\n",
    "plt.xlabel(\"Inlier thresholds\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Distribution of Inlier Thresholds\")\n",
    "\n",
    "plt.grid(True)\n",
    "plt.xlim(0, max(max(thresholds)))  # Set limits for silhouette scores (typically between -1 and 1)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d030bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean and variance of the inlier thresholds distribution\n",
    "mean = np.mean(np.abs(list(chain.from_iterable(thresholds))))\n",
    "var = np.var(np.abs(list(chain.from_iterable(thresholds))))\n",
    "median = st.median(np.abs(list(chain.from_iterable(thresholds))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# median thresholds\n",
    "med_thresholds=[st.median(t) for t in thresholds]\n",
    "\n",
    "\n",
    "print(f\"The threshold distribution has mean: {mean} and variance: {var}\")\n",
    "print(f\"The threshold distribution has median: {median}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ffc118",
   "metadata": {},
   "source": [
    "# Outlier detection using new inlier thresholds with GC RANSAC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4710dd59",
   "metadata": {},
   "source": [
    "### Plot residual matrices and outliers using gc-ransac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774fe63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_data_to_analyse=len(names)\n",
    "plot_heat=True\n",
    "\n",
    "for i in range(number_of_data_to_analyse):\n",
    "    data=mat_data[names[i]]\n",
    "    res=build_residual_matrix(data, plot=True, method=\"gc-ransac\" , threshold=thresholds[i], verbose=True)\n",
    "    \n",
    "    labl=mat_data[names[i]][\"label\"]\n",
    "    mod_lab=np.where(labl>0)\n",
    "    labl=labl[mod_lab].reshape(-1,1)\n",
    "    labl=labl/np.max(labl)\n",
    "    labl=labl*np.max(res)\n",
    "    \n",
    "    if plot_heat:\n",
    "        plot_residual_matrix(res,labl)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ca371c",
   "metadata": {},
   "source": [
    "# Analysis of residual curves of GC RANSAC with new thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e121e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input parameter, how many files to analyse\n",
    "number_of_data_to_analyse=len(names)\n",
    "\n",
    "\n",
    "\n",
    "silhouette_scores_gc = [[] for i in range(number_of_data_to_analyse)]\n",
    "silhouette_avgs_gc = [[] for i in range(number_of_data_to_analyse)]\n",
    "labels_array_gc = [[] for i in range(number_of_data_to_analyse)]\n",
    "residuals_gc = []\n",
    "values_array_gc = [[] for i in range(number_of_data_to_analyse)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(number_of_data_to_analyse):\n",
    "    data=mat_data[names[i]]\n",
    "    \n",
    "    img1, img2 = data[\"img1\"], data[\"img2\"]\n",
    "\n",
    "    outliers, models = vi.group_models(data)[\"outliers\"], vi.group_models(data)[\"models\"]\n",
    "    \n",
    "    points=extract_points(models,data)\n",
    "    \n",
    "    labels = points[3]\n",
    "    \n",
    "    points=points[0]\n",
    "    \n",
    "    res=build_residual_matrix(data, plot=False, verbose=False,method=\"gc-ransac\" , threshold=thresholds[i])\n",
    "\n",
    "\n",
    "    for j in range(len(models)):\n",
    "        \n",
    "        src = points[\"src_points\"][j]\n",
    "        dst = points[\"dst_points\"][j]\n",
    "        \n",
    "        _,lbl=verify_pygcransac_H(src,dst,img1,img1,med_thresholds[i], verbose=False)\n",
    "         \n",
    "        lbl=1-lbl\n",
    "        \n",
    "        residuals_of_model=res[np.where(labels==j+1),j]\n",
    "        \n",
    "        sort_index=np.argsort(residuals_of_model.ravel())\n",
    "        \n",
    "        sorted_res=residuals_of_model.ravel()[sort_index]\n",
    "        \n",
    "        sorted_lbl=lbl[sort_index]\n",
    "        \n",
    "        \n",
    "        \n",
    "        if len(np.unique(sorted_lbl))!=1:\n",
    "            labels_array_gc[i].append(sorted_lbl)\n",
    "            silhouette_scr, silhouette_avg, values = silhouette_score_and_average(sorted_res, sorted_lbl)\n",
    "            silhouette_scores_gc[i].append(silhouette_scr)\n",
    "            silhouette_avgs_gc[i].append(silhouette_avg)\n",
    "            values_array_gc[i].append(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ecb669",
   "metadata": {},
   "source": [
    "### Residual curves of gc ransac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(silhouette_scores_gc)):\n",
    "    for j in range(len(silhouette_scores_gc[i])):\n",
    "        plot_silhouette(silhouette_scores_gc[i][j], labels_array_gc[i][j], silhouette_avgs_gc[i][j], values_array_gc[i][j], -med_thresholds[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd771cdf",
   "metadata": {},
   "source": [
    "### Residual curves of LMEDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdfbb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(silhouette_scores)):\n",
    "    for j in range(len(silhouette_scores[i])):\n",
    "        plot_silhouette(silhouette_scores[i][j], labels_array[i][j], silhouette_avgs[i][j], values_array[i][j], -thresholds[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a08fc0",
   "metadata": {},
   "source": [
    "### AVG silhouette score LMEDS vs GC RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c159ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten_avgs_LMEDS=[value for  sublist in silhouette_avgs for value in sublist]\n",
    "flatten_avgs_GCRANSAC=[value for  sublist in silhouette_avgs_gc for value in sublist]\n",
    "\n",
    "print(\"LMEDS avarage silhhouette: \" , np.mean(flatten_avgs_LMEDS))\n",
    "print(\"GC-RANSAC avarage silhhouette: \" , np.mean(flatten_avgs_GCRANSAC))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f138a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8499b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d67d86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
